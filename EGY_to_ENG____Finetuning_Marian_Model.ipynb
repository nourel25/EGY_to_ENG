{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "mfVvpraqZFR5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK6TNNw5U-cU"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"Helsinki-NLP/opus-mt-ar-en\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN7i9XIeO6vq"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline('translation', model=model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVOO92AdR40k"
      },
      "outputs": [],
      "source": [
        "translator('أنت شخصية توكسيك')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4YviUAMSLc2"
      },
      "outputs": [],
      "source": [
        "translator('أنا مبفكرش في عيالي؟')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW0EamP6TMDN"
      },
      "outputs": [],
      "source": [
        "translator('‫عشان خاطري.‬')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8hDkdFTTwnT"
      },
      "outputs": [],
      "source": [
        "translator('يا علا!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lx4DFlTUZvY"
      },
      "outputs": [],
      "source": [
        "translator('طب وأنتي كويسه؟')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFAD0c-GLEMa"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TScetPDLJiJx"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"HeshamHaroon/ArzEn-MultiGenre\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5X4MwbvLkBd"
      },
      "outputs": [],
      "source": [
        "raw_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparing"
      ],
      "metadata": {
        "id": "aLCaaK1pYZ57"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHLlg6LmOLYm"
      },
      "outputs": [],
      "source": [
        "split_datasets = raw_datasets['train'].train_test_split(train_size=0.9, seed=20)\n",
        "split_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KDCoc2hOXGR"
      },
      "outputs": [],
      "source": [
        "split_datasets['validation'] = split_datasets.pop('test')\n",
        "split_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWf7hh4RO26h"
      },
      "outputs": [],
      "source": [
        "split_datasets['train'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer Loading"
      ],
      "metadata": {
        "id": "CQ_R6jCiZLaR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waf-g0AeUoBb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhZk0US7U6_I"
      },
      "outputs": [],
      "source": [
        "eg_sentence = split_datasets['train']['EGY'][0]\n",
        "en_sentence = split_datasets['train']['ENG'][0]\n",
        "\n",
        "inputs = tokenizer(eg_sentence, text_target=en_sentence)\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfVzl6NcZ4W7"
      },
      "outputs": [],
      "source": [
        "split_datasets[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7D-1FaeecMW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).strip()\n",
        "    text = text.replace('\\u200f', '')  # remove RTL marks\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjP2_PwCWreH"
      },
      "outputs": [],
      "source": [
        "max_length = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Ensure that each example is a list of strings\n",
        "    inputs = [clean_text(text) for text in examples[\"EGY\"]]\n",
        "    targets = [clean_text(text) for text in examples[\"ENG\"]]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        text_target=targets,\n",
        "        max_length=max_length,\n",
        "        truncation=True\n",
        "    )\n",
        "    return model_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1wdlp3KXmTx"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = split_datasets.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=split_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C59Juw2adcJa"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1dS8LDLa-kF"
      },
      "source": [
        "## Data Collation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwZiIDs5brrp"
      },
      "source": [
        "##### DataCollatorWithPadding only pads the inputs, so we need to pad the labels and the pad token for labels is -100 to make sure those padded values are ignored in the loss computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqyqd7dJa42a"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjTkqc-AbcIk"
      },
      "outputs": [],
      "source": [
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfwbM1dFbfY5"
      },
      "outputs": [],
      "source": [
        "batch[\"labels\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWPAwV51aGAQ"
      },
      "source": [
        "# **Fine-tuning the model - Trainer API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0taNtsZYpzP"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJmyZHD-bmXS"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgmoBaNqfwmK"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQxa76sHgFU2"
      },
      "outputs": [],
      "source": [
        "# Example reference and predictions\n",
        "predictions = [\n",
        "    \"The cat is on the mat\",\n",
        "    \"There is a cat sitting on the floor\"\n",
        "]\n",
        "\n",
        "references = [\n",
        "    [\"The cat is on the mat\"],  # each reference list can contain multiple valid translations\n",
        "    [\"A cat is sitting on the floor\"]\n",
        "]\n",
        "\n",
        "res = metric.compute(predictions=predictions, references=references)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYp_8RhJij8D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # In case the model returns more than the prediction logits\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100s in the labels as we can't decode them\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters Search with optuna"
      ],
      "metadata": {
        "id": "ODZXRCMzZ3Ay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1uwJn2LwPA2"
      },
      "outputs": [],
      "source": [
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rRcbeZCxS5b"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    return AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wbctkHeuUUG"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def hp_space_optuna(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.05, 0.2),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 3, 6),\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\n",
        "            \"lr_scheduler_type\", [\"linear\", \"cosine\", \"polynomial\"]\n",
        "        ),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skAnhgpuvwH1"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args  = Seq2SeqTrainingArguments(\n",
        "    f'marian-finetuned-ArzEn-MultiGenre-egy-to-en',\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='no',\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to='none',\n",
        "    load_best_model_at_end=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg68sM3Xv30t"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyfHQFItv7Pr"
      },
      "outputs": [],
      "source": [
        "best_run = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",  # we want highest BLEU\n",
        "    hp_space=hp_space_optuna,\n",
        "    compute_objective=lambda metrics: metrics[\"eval_bleu\"],\n",
        "    n_trials=10,  # try 10 different combinations\n",
        ")\n",
        "print(\"Best run:\", best_run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLxE9UKhwLd_"
      },
      "outputs": [],
      "source": [
        "best_args = best_run.hyperparameters\n",
        "best_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sExivRfy3AI"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "final_args = Seq2SeqTrainingArguments(\n",
        "    f'marian-finetuned-ArzEn-MultiGenre-egy-to-en',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=0.00013501528621462957,\n",
        "    lr_scheduler_type='polynomial',\n",
        "    warmup_ratio=0.07805866417161107,\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"bleu\",\n",
        "    greater_is_better=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rxzVSM0zA1L"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "final_trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args=final_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D7fWSD7n8eJ"
      },
      "source": [
        "\n",
        "\n",
        "## Before fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcWgHGf8nElF"
      },
      "outputs": [],
      "source": [
        "final_trainer.evaluate(max_length=max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "rBf02XJLaGXU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THGJkeBfocAn"
      },
      "outputs": [],
      "source": [
        "final_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMiV4eO7oYc5"
      },
      "source": [
        "## After fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM8seX7goBUC"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(max_length=max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Push the model into HuggingFace Hub"
      ],
      "metadata": {
        "id": "9rJy5bRcZpd4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2U9qYRof0uM"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJNQLQVBmi0A"
      },
      "outputs": [],
      "source": [
        "final_trainer.push_to_hub(commit_message=\"Improved BLEU to 23.0 with 10 trials by optuna\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try the model"
      ],
      "metadata": {
        "id": "Qis1D6q1aKpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxNbOXaQrTAs"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_checkpoint = 'NEldin10/marian-finetuned-ArzEn-MultiGenre-egy-to-en'\n",
        "translator = pipeline(\"translation\", model=model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciHC8q-MrndQ"
      },
      "outputs": [],
      "source": [
        "translator('أنت شخصية توكسيك')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yow9ORgjrvf7"
      },
      "outputs": [],
      "source": [
        "translator('أنا مبفكرش في عيالي؟')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6kI3TsFr0eO"
      },
      "outputs": [],
      "source": [
        "translator('‫عشان خاطري.‬')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydclsW5mr6S-"
      },
      "outputs": [],
      "source": [
        "translator('يا علا!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7r98-I0sJqS"
      },
      "outputs": [],
      "source": [
        "translator('طب وأنتي كويسه؟')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAANIWE5sM9Z"
      },
      "outputs": [],
      "source": [
        "translator('إيه يا سليم، بتدور على إيه يا حبيبي؟‬')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3IuR6eesTZb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}